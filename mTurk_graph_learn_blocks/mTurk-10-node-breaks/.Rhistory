# there shouldn't be any NaNs, but if there are skip
if (any(is.nan(node_data$spike_num)) | any(is.na(node_data$spike_num))){
warning("This dataset had NaN spike numbers: check the spreadsheet")
next
}
# drop hg phase locking - PLV not interpretable for wide band signals
node_data <- filter(node_data, band_measure != "hg_plv")
node_data <- filter(node_data, band_measure != "hg_iplv")
# remove duplicate time points, if present
node_data <- node_data %>% distinct()
# get network level strength separated by soz and not soz
net_data <- group_by(node_data, sess_exper, time, spike_num, spike_spread, bin_spike, fc_measure, band, band_measure) %>%
dplyr::summarise(str = mean(str, na.rm=TRUE), str_spike = mean(str_spike, na.rm=TRUE),
str_not_spike = mean(str_not_spike, na.rm=TRUE), ti = mean(ti, na.rm=TRUE),  power = mean(power))
# for soz networks, you can't average over all elecs, have to break them up
tmp_soz = group_by(node_data, elec_in_soz, sess_exper, time, spike_num, bin_spike, spike_spread, fc_measure, band, band_measure) %>%
dplyr::summarise(str_soz = mean(str_soz, na.rm=TRUE), str_not_soz = mean(str_not_soz, na.rm=TRUE))
# remove not soz elecs from str_soz, and visa versa
tmp_soz$str_soz[tmp_soz$elec_in_soz == 0] <- NA
tmp_soz$str_not_soz[tmp_soz$elec_in_soz == 1] <- NA
# now colapse over elec_in_soz
tmp_soz <- group_by(node_data, sess_exper, time, spike_num, spike_spread, bin_spike, fc_measure, band, band_measure) %>%
dplyr::summarise(str_soz = mean(str_soz, na.rm=TRUE), str_not_soz = mean(str_not_soz, na.rm=TRUE))
# now merge on shared features (subj, band, time, etc)
net_data = merge(net_data, tmp_soz, by = c('sess_exper', 'time', 'spike_num','spike_spread', 'bin_spike', "fc_measure", 'band', 'band_measure'))
# add constants
net_data[const_vars] = node_data[const_vars][1,]
# plots
if (save_plot){
p1 <- ggplot(data=net_data[net_data$spike_num != 0,], aes(x=spike_num)) + geom_histogram() + theme_minimal()
p2 <-ggplot(data=net_data[net_data$spike_spread != 0,], aes(x=spike_spread)) + geom_histogram() + theme_minimal()
p3 <- ggplot(data=net_data[net_data$spike_num != 0,], aes(x=str, color=band, fill=as.factor(fc_measure))) +
geom_histogram(alpha=0.7) + theme_minimal() + scale_fill_manual(values=park_palette("GeneralGrant")) + scale_color_grey()
p <- grid.arrange(p1, p2, p3, nrow=3)
ggsave(paste(RAM_dir, 'img/models/', net_data$subj, '_net_hist.png', sep=''), plot=p, device = 'png')
}
# for every fc_meansure and band, fit network model
try({
curr_net_beta <- group_by(net_data, band_measure) %>%
group_modify(~ get_beta(.x,ys, form)) %>%
dplyr::summarise(n_tp = length(time), str_beta_bin = str_beta_bin[1], str_beta_num =
str_beta_num[1], str_beta_spr = str_beta_spr[1], ti_beta_bin =
ti_beta_bin[1], ti_beta_num = ti_beta_num[1], ti_beta_spr = ti_beta_spr[1],
str_soz_beta_bin = str_soz_beta_bin[1],  str_soz_beta_num =
str_soz_beta_num[1], str_soz_beta_spr = str_soz_beta_spr[1],
str_not_soz_beta_num = str_not_soz_beta_num[1], str_spike_beta_num =
str_spike_beta_num[1], str_not_soz_beta_spr =
str_not_soz_beta_spr[1],str_not_soz_beta_bin = str_not_soz_beta_bin[1],
str_spike_beta_bin = str_spike_beta_bin[1], str_spike_beta_spr =
str_spike_beta_spr[1],str_not_spike_beta_bin =
str_not_spike_beta_bin[1],fc_measure = fc_measure[1], str_not_spike_beta_num
= str_not_spike_beta_num[1], str_not_spike_beta_spr =
str_not_spike_beta_spr[1], band = band[1])
curr_net_beta[const_vars] <- net_data[const_vars][1,]
# concatenate
net_betas <- suppressWarnings(bind_rows(curr_net_beta, net_betas)) # silence warnings about converting factors to strings
})
# fit node models
try({
curr_node_beta <- group_by(node_data, elec, band_measure) %>%
group_modify(~ get_beta(.x,ys, form)) %>%
dplyr::summarise(n_tp = length(time), elec_spike = mean(elec_has_spike),
elec_in_soz = elec_in_soz[1], str_soz_beta_bin = str_soz_beta_bin[1],
str_not_soz_beta_bin = str_not_soz_beta_bin[1], str_spike_beta_bin =
str_spike_beta_bin[1], str_not_spike_beta_bin =
str_not_spike_beta_bin[1], str_beta_bin = str_beta_bin[1],
str_soz_beta_num = str_soz_beta_num[1], str_not_soz_beta_num =
str_not_soz_beta_num[1], str_spike_beta_num = str_spike_beta_num[1],
str_beta_num = str_beta_num[1],str_not_spike_beta_num =
str_not_spike_beta_num[1], ti_beta_bin = ti_beta_bin[1], ti_beta_num =
ti_beta_num[1], ti_beta_spr = ti_beta_spr[1], str_beta_spr =
str_beta_spr[1], str_soz_beta_spr = str_soz_beta_spr[1],
str_not_soz_beta_spr = str_not_soz_beta_spr[1], str_spike_beta_spr =
str_spike_beta_spr[1], str_not_spike_beta_spr =
str_not_spike_beta_spr[1], fc_measure =
fc_measure[1], band = band[1], region = region[1], x = x[1],
y = y[1], z = z[1], type = type[1])
curr_node_beta[const_vars] <- net_data[const_vars][1,]
#  concetenate
node_betas <- suppressWarnings(bind_rows(curr_node_beta, node_betas)) # silence warnings about converting factors to strings
})
}
}
}
# save betas
write.csv(net_betas, file = paste(RAM_dir, 'group_analysis/win_', as.character(win), '/network_stats', detector, '.csv', sep=''))
knitr::opts_chunk$set(echo = TRUE)
# clean workspace
rm(list=ls())
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, dplyr, lm.beta, RColorBrewer, nationalparkcolors, rjson, reticulate, gridExtra, wesanderson, MASS, outliers, lmerTest, stringr, lmPerm)
# set up python for later
use_python("/Users/stiso/anaconda3/bin/python") # path to python binary
py_config() # check it is using the specified version
# directory for RAM data, request from XXX
RAM_dir = '/Volumes/bassett-data/Jeni/RAM/'
# parameters
win = 1
detector = '_delphos'
net_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_data_clean', detector, '.csv',sep=''))
net_data$race = as.factor(net_data$race)
soz_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_soz_data_clean', detector ,'.csv',sep=''))
soz_data$race = as.factor(soz_data$race)
soz_data <- mutate(soz_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
spike_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_spike_data_clean', detector, '.csv',sep=''))
spike_data$race = as.factor(spike_data$race)
spike_data <- mutate(spike_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
pred = 'spr'# bin or num or spr
aec_flag = 'aec$' # which aec do you want to EXCLUDE, orth or regular. The carrot mean "starts with", $                      means 'ends with'
coh_flag = '^coh' #
plv_flag = 'iplv$'
curr_measures = net_data[!grepl(aec_flag, net_data$Measure) & !grepl(coh_flag, net_data$Measure) & !grepl(plv_flag, net_data$Measure), 'band_measure']
bfc = unique(curr_measures)
ps = list()
ts = list()
df = list()
for (m in bfc){
print(m)
curr <- filter(net_data, band_measure == m)
y = unlist(na.omit(curr[paste('str_beta_', pred, sep='')]))
stat <- t.test(y)
print(stat)
ps = c(ps, stat$p.value)
ts = c(ts, stat$statistic)
df = c(df, stat$parameter)
}
# corrections based on aec or aec_orth, not both
stats = data.frame(p = p.adjust(ps, method='bonferroni'), t = unlist(ts), df = unlist(df), measure = bfc, sig = p.adjust(ps, method="bonferroni") < 0.05)
stats
pred = 'nuum'# bin or num or spr
aec_flag = 'aec$' # which aec do you want to EXCLUDE, orth or regular. The carrot mean "starts with", $                      means 'ends with'
coh_flag = '^coh' #
plv_flag = 'iplv$'
curr_measures = net_data[!grepl(aec_flag, net_data$Measure) & !grepl(coh_flag, net_data$Measure) & !grepl(plv_flag, net_data$Measure), 'band_measure']
bfc = unique(curr_measures)
ps = list()
ts = list()
df = list()
for (m in bfc){
print(m)
curr <- filter(net_data, band_measure == m)
y = unlist(na.omit(curr[paste('str_beta_', pred, sep='')]))
stat <- t.test(y)
print(stat)
ps = c(ps, stat$p.value)
ts = c(ts, stat$statistic)
df = c(df, stat$parameter)
}
pred = 'num'# bin or num or spr
aec_flag = 'aec$' # which aec do you want to EXCLUDE, orth or regular. The carrot mean "starts with", $                      means 'ends with'
coh_flag = '^coh' #
plv_flag = 'iplv$'
curr_measures = net_data[!grepl(aec_flag, net_data$Measure) & !grepl(coh_flag, net_data$Measure) & !grepl(plv_flag, net_data$Measure), 'band_measure']
bfc = unique(curr_measures)
ps = list()
ts = list()
df = list()
for (m in bfc){
print(m)
curr <- filter(net_data, band_measure == m)
y = unlist(na.omit(curr[paste('str_beta_', pred, sep='')]))
stat <- t.test(y)
print(stat)
ps = c(ps, stat$p.value)
ts = c(ts, stat$statistic)
df = c(df, stat$parameter)
}
# corrections based on aec or aec_orth, not both
stats = data.frame(p = p.adjust(ps, method='bonferroni'), t = unlist(ts), df = unlist(df), measure = bfc, sig = p.adjust(ps, method="bonferroni") < 0.05)
stats
pred = 'bin'# bin or num or spr
aec_flag = 'aec$' # which aec do you want to EXCLUDE, orth or regular. The carrot mean "starts with", $                      means 'ends with'
coh_flag = '^coh' #
plv_flag = 'iplv$'
curr_measures = net_data[!grepl(aec_flag, net_data$Measure) & !grepl(coh_flag, net_data$Measure) & !grepl(plv_flag, net_data$Measure), 'band_measure']
bfc = unique(curr_measures)
ps = list()
ts = list()
df = list()
for (m in bfc){
print(m)
curr <- filter(net_data, band_measure == m)
y = unlist(na.omit(curr[paste('str_beta_', pred, sep='')]))
stat <- t.test(y)
print(stat)
ps = c(ps, stat$p.value)
ts = c(ts, stat$statistic)
df = c(df, stat$parameter)
}
# corrections based on aec or aec_orth, not both
stats = data.frame(p = p.adjust(ps, method='bonferroni'), t = unlist(ts), df = unlist(df), measure = bfc, sig = p.adjust(ps, method="bonferroni") < 0.05)
stats
pred = 'spr'# bin or num or spr
aec_flag = 'aec$' # which aec do you want to EXCLUDE, orth or regular. The carrot mean "starts with", $                      means 'ends with'
coh_flag = '^coh' #
plv_flag = 'iplv$'
curr_measures = net_data[!grepl(aec_flag, net_data$Measure) & !grepl(coh_flag, net_data$Measure) & !grepl(plv_flag, net_data$Measure), 'band_measure']
bfc = unique(curr_measures)
ps = list()
ts = list()
df = list()
for (m in bfc){
print(m)
curr <- filter(net_data, band_measure == m)
y = unlist(na.omit(curr[paste('ti_beta_', pred, sep='')]))
stat <- t.test(y)
print(stat)
ps = c(ps, stat$p.value)
ts = c(ts, stat$statistic)
df = c(df, stat$parameter)
}
# corrections based on aec or aec_orth, not both
stats = data.frame(p = p.adjust(ps, method='bonferroni'), t = unlist(ts), df = unlist(df), measure = bfc, sig = p.adjust(ps, method="bonferroni") < 0.05)
stats
net_data <-mutate(net_data, band_measure_clean = tolower(paste(Frequency.Band, Measure, sep = '_')))
keep_measures = c('theta_aec_ortho', 'theta_im_coh', 'alpha_aec_ortho',  'beta_aec_ortho', 'beta_im_coh', 'gamma_aec_ortho', 'gamma_im_coh', 'high gamma_aec_ortho',
'high gamma_im_coh')
bm = unique(net_data$band_measure_clean)
supp_measures = bm[which(!bm %in% keep_measures)]
node_keep_measures = c('theta_aec_ortho', 'theta_im_coh','alpha_aec_ortho',  'beta_aec_ortho', 'beta_im_coh', 'gamma_aec_ortho', 'gamma_im_coh', 'hg_aec_ortho',
'hg_im_coh')
# general task performance
pred = 'bin'
supp_flag = FALSE # are you using main measures, or supplemental measures
task_ps = list()
task_df = list()
task_ts = list()
tasks = c('TH', 'YC', 'PAL', 'FR', 'catFR')
net_task_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_task_data_clean', detector, '.csv', sep=''))
net_task_data$race <- as.factor(net_task_data$race)
net_task_data <- mutate(net_task_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
net_task_data$band_measure <- tolower(net_task_data$band_measure)
if (supp_flag){
# loop through other measures and remove...probably a better way to do this
for (m in keep_measures){
net_task_data = dplyr::filter(net_task_data, band_measure != m)
}
}else {
for (m in supp_measures){
net_task_data = dplyr::filter(net_task_data, band_measure != m)
}
}
fc = unique(net_task_data$band_measure)
fc = fc[fc != 'high gamma_iplv']
for (m in fc){
print(m)
curr = dplyr::filter(net_task_data, band_measure == m)
curr = curr[!is.na(curr[,paste('str_beta_', pred, sep='')]),]
nObs = dim(curr)[1]
nRow = dim(resid)[1]
fit = lm(data=curr, paste('pca1 ~ str_beta_', pred, '+ race + gender + age + hand + Education + Etiology + SeizureAge', sep=''))
print(anova(fit))
# get stats
task_ps = c(task_ps, summary(fit)$coefficients[2,'Pr(>|t|)'])
task_ts = c(task_ts, summary(fit)$coefficients[2,'t value'])
task_df = c(task_df, summary(fit)$df[2])
}
# general task performance
pred = 'bin'
supp_flag = FALSE # are you using main measures, or supplemental measures
task_ps = list()
task_df = list()
task_ts = list()
tasks = c('TH', 'YC', 'PAL', 'FR', 'catFR')
net_task_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_task_data_clean', detector, '.csv', sep=''))
net_task_data$race <- as.factor(net_task_data$race)
net_task_data <- mutate(net_task_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
net_task_data$band_measure <- tolower(net_task_data$band_measure)
if (supp_flag){
# loop through other measures and remove...probably a better way to do this
for (m in keep_measures){
net_task_data = dplyr::filter(net_task_data, band_measure != m)
}
}else {
for (m in supp_measures){
net_task_data = dplyr::filter(net_task_data, band_measure != m)
}
}
fc = unique(net_task_data$band_measure)
fc = fc[fc != 'high gamma_iplv']
for (m in fc){
print(m)
curr = dplyr::filter(net_task_data, band_measure == m)
curr = curr[!is.na(curr[,paste('str_beta_', pred, sep='')]),]
nObs = dim(curr)[1]
nRow = dim(resid)[1]
fit = lm(data=curr, paste('pca1 ~ str_beta_', pred, '+ race + gender + age + hand + Education + Etiology + SeizureAge', sep=''))
print(anova(fit))
# get stats
task_ps = c(task_ps, summary(fit)$coefficients[2,'Pr(>|t|)'])
task_ts = c(task_ts, summary(fit)$coefficients[2,'t value'])
task_df = c(task_df, summary(fit)$df[2])
}
task_stats = data.frame(p = unlist(task_ps), f = unlist(task_ts), df = unlist(task_df), band_measure = fc, sigMC = p.adjust(task_ps, method = 'bonferroni') < 0.05, sig = task_ps < 0.05)
task_stats
# general task performance
pred = 'spr'
supp_flag = FALSE # are you using main measures, or supplemental measures
task_ps = list()
task_df = list()
task_ts = list()
tasks = c('TH', 'YC', 'PAL', 'FR', 'catFR')
net_task_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_task_data_clean', detector, '.csv', sep=''))
net_task_data$race <- as.factor(net_task_data$race)
net_task_data <- mutate(net_task_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
net_task_data$band_measure <- tolower(net_task_data$band_measure)
if (supp_flag){
# loop through other measures and remove...probably a better way to do this
for (m in keep_measures){
net_task_data = dplyr::filter(net_task_data, band_measure != m)
}
}else {
for (m in supp_measures){
net_task_data = dplyr::filter(net_task_data, band_measure != m)
}
}
fc = unique(net_task_data$band_measure)
fc = fc[fc != 'high gamma_iplv']
for (m in fc){
print(m)
curr = dplyr::filter(net_task_data, band_measure == m)
curr = curr[!is.na(curr[,paste('str_beta_', pred, sep='')]),]
nObs = dim(curr)[1]
nRow = dim(resid)[1]
fit = lm(data=curr, paste('pca1 ~ str_beta_', pred, '+ race + gender + age + hand + Education + Etiology + SeizureAge', sep=''))
print(anova(fit))
# get stats
task_ps = c(task_ps, summary(fit)$coefficients[2,'Pr(>|t|)'])
task_ts = c(task_ts, summary(fit)$coefficients[2,'t value'])
task_df = c(task_df, summary(fit)$df[2])
}
task_stats = data.frame(p = unlist(task_ps), f = unlist(task_ts), df = unlist(task_df), band_measure = fc, sigMC = p.adjust(task_ps, method = 'bonferroni') < 0.05, sig = task_ps < 0.05)
task_stats
# general task performance
pred = 'bin'
supp_flag = FALSE # are you using main measures, or supplemental measures
task_ps = list()
task_df = list()
task_ts = list()
tasks = c('TH', 'YC', 'PAL', 'FR', 'catFR')
net_task_data = read.csv(paste('/Volumes/bassett-data/Jeni/RAM/group_analysis/win_', as.character(win), '/net_task_data_clean', detector, '.csv', sep=''))
net_task_data$race <- as.factor(net_task_data$race)
net_task_data <- mutate(net_task_data, band_measure = paste(Frequency.Band, Measure, sep = '_'))
net_task_data$band_measure <- tolower(net_task_data$band_measure)
if (supp_flag){
# loop through other measures and remove...probably a better way to do this
for (m in keep_measures){
net_task_data = dplyr::filter(net_task_data, band_measure != m)
}
}else {
for (m in supp_measures){
net_task_data = dplyr::filter(net_task_data, band_measure != m)
}
}
fc = unique(net_task_data$band_measure)
fc = fc[fc != 'high gamma_iplv']
for (m in fc){
print(m)
curr = dplyr::filter(net_task_data, band_measure == m)
curr = curr[!is.na(curr[,paste('str_beta_', pred, sep='')]),]
nObs = dim(curr)[1]
nRow = dim(resid)[1]
fit = lm(data=curr, paste('pca1 ~ str_beta_', pred, '+ race + gender + age + hand + Education + Etiology + SeizureAge', sep=''))
print(anova(fit))
# get stats
task_ps = c(task_ps, summary(fit)$coefficients[2,'Pr(>|t|)'])
task_ts = c(task_ts, summary(fit)$coefficients[2,'t value'])
task_df = c(task_df, summary(fit)$df[2])
}
task_stats = data.frame(p = unlist(task_ps), f = unlist(task_ts), df = unlist(task_df), band_measure = fc, sigMC = p.adjust(task_ps, method = 'bonferroni') < 0.05, sig = task_ps < 0.05)
task_stats
library(ggplot2)
library(dplyr)
library(coin)
library(lmPerm)
library(car)
library(aplpack)
library(lmerTest)
library(RColorBrewer)
library(wesanderson)
library(nationalparkcolors)
library(ez)
library(plyr)
setwd("/Users/stiso/Documents/Python/graphLearning/old_tasks/mTurk-10-node-breaks")
ext = '1'
df = read.csv('experiment/data/preprocessed/taskdata.csv.gz')
summary(df)
acc = dplyr::filter(df, nTries == 1, stage != 'demo') %>%
group_by(workerid) %>%
dplyr::summarise(total_acc = table(correct)["True"]/10)
p<-ggplot(acc, aes(x=total_acc)) +
geom_histogram(fill='lightblue', color='white')
p
summary(acc$total_acc)
subj_rm = df$workerid == acc$workerid[acc$total_acc < 80]
df = df[!subj_rm,]
df_clean = subset(df, select = -c(target,query,phase,node,event))
df_clean = na.omit(df_clean)
summary(df_clean)
df_clean = dplyr::filter(df_clean, stage != 'demo')
cat_vars = c('keyCode', 'workerid','stage', 'hand','hand_transition','is_crosscluster', 'correct')
df = read.csv('experiment/data/preprocessed/taskdata.csv.gz')
summary(df)
acc = dplyr::filter(df, nTries == 1, stage != 'demo') %>%
group_by(workerid) %>%
dplyr::summarise(total_acc = table(correct)["True"]/10)
p<-ggplot(acc, aes(x=total_acc)) +
geom_histogram(fill='lightblue', color='white')
p
summary(acc$total_acc)
df_clean = subset(df, select = -c(target,query,phase,node,event))
df_clean = na.omit(df_clean)
summary(df_clean)
df_clean = dplyr::filter(df_clean, stage != 'demo')
cat_vars = c('keyCode', 'workerid','stage', 'hand','hand_transition','is_crosscluster', 'correct')
for (var in cat_vars){
df_clean[var] =
as.factor(unlist(df_clean[var]))
}
df_clean = filter(df_clean, rt < 2000)
df_clean = filter(df_clean, rt > 50)
cum_trial = df_clean$trial
df_clean$stage_num = rep(0, times = length(cum_trial))
for (t in 1:length(cum_trial)){
curr_stage = df_clean$stage[t]
if (curr_stage == "walk_two"){
cum_trial[t] = df_clean$trial[t] + 250
df_clean$stage_num[t] = 2
} else if (curr_stage == "walk_three"){
cum_trial[t] = df_clean$trial[t] + 250*2
df_clean$stage_num[t] = 3
} else if (curr_stage == "walk_four"){
cum_trial[t] = df_clean$trial[t] + 250*3
df_clean$stage_num[t] = 4
} else {
df_clean$stage_num[t] = 1
}
}
df_clean$cum_trial = cum_trial
df_clean$log_cum_trial = log10(df_clean$cum_trial + 1)
df_clean$trial = df_clean$trial + 1
finger = character(length = length(df_clean$keyCode))
for (t in 1:length(finger)){
curr_key = df_clean$keyCode[t]
if (curr_key == 81 | curr_key == 80){
finger[t] = 'pinky'
} else if (curr_key == 87 | curr_key == 79){
finger[t] = 'ring'
} else if (curr_key == 69 | curr_key == 73){
finger[t] = 'middle'
} else if (curr_key == 82 | curr_key == 85){
finger[t] = 'index'
} else if (curr_key == 86 | curr_key == 66){
finger[t] = 'thumb'
} else {
finger[t] = NA
}
}
df_clean$finger = as.factor(finger)
p<-ggplot(df_clean, aes(x=rt)) +
geom_histogram(fill='pink', color='white')
p
ggsave(paste( '/data/preprocessed/images/rt', ext,'.png', sep = ''))
df_clean$rt_raw = df_clean$rt
df_clean$rt = log10(df_clean$rt)
p<-ggplot(df_clean, aes(x=rt)) +
geom_histogram(fill='lightblue', color='white')
p
ggsave(paste( 'experiment/data/preprocessed/images/rt_log', ext,'.png', sep = ''))
summary(df_clean)
df_correct = dplyr::filter(df_clean, correct == "True" & nTries == 1)
df_correct = subset(df_correct, select = -c(correct, nTries))
df_acc = filter(df_clean, nTries == 1)
df_acc$correct = as.factor(as.integer(df_acc$correct))
df_modular_acc = filter(df_acc, is_lattice == 0)
df_left = filter(df_modular, hand == 'left')
df_right = filter(df_modular, hand == 'right')
summary(df_correct)
stop_num = 10
f = function(x) {
if (x > stop_num) {
y = stop_num
} else {
y = x
}
return(y)
}
nuissance_reg = lmer(data=df_correct, rt~scale(log10(cum_trial)) + scale(log10(trial)) + finger + hand + hand_transition + stage_num +
(1 + scale(log10(cum_trial))|workerid))
recency_fact = lapply(df_correct$recency, f)
df_correct$recency_fact = unlist(recency_fact)
df_modular = filter(df_correct, is_lattice == 0)
recency_data = data.frame( rt = resid(nuissance_reg), lag10 = df_correct$lag10, recency = df_correct$recency, graph = as.factor(df_correct$is_lattice),
subj = df_correct$workerid, recency_fact = (unlist(recency_fact)))
stat_learn = lmer(data=df_correct, rt~scale(log10(cum_trial)) + scale(log10(trial)) + finger + hand + hand_transition + stage_num + scale(log(recency_fact)) +
(1 + scale(log10(cum_trial)) + scale(log(recency_fact))|workerid))
anova(stat_learn)
df_modular$resid = resid(lmer(data=df_correct, rt~scale(log10(cum_trial)) + scale(log(recency_fact)) + finger + hand + hand_transition + stage_num + log10(recency) +
(1 + scale(log10(cum_trial)) + scale(log(recency_fact))|workerid)))
max_ent_data = select(df_correct, c('walk_id', 'workerid', 'trial', 'is_lattice'))
max_ent_data$resid = resid(stat_learn)
write.csv(max_ent_data, file = 'data/preprocessed/residuals.csv')
stat_learn = lmer(data=df_correct, rt~scale(log10(cum_trial)) + scale(log10(trial)) + finger + hand + hand_transition + stage_num + scale(log(recency_fact)) +
(1 + scale(log10(cum_trial)) + scale(log(recency_fact))|workerid))
max_ent_data = select(df_correct, c('walk_id', 'workerid', 'trial', 'is_lattice'))
max_ent_data$resid = resid(stat_learn)
write.csv(max_ent_data, file = 'data/preprocessed/residuals.csv')
length(unique(df_correct$workerid))
length(unique(max_ent_data$workerid))
write.csv(max_ent_data, file = 'data/preprocessed/residuals.csv')
setwd("/Users/stiso/Documents/Python/graphLearning/old_tasks/mTurk-10-node-breaks")
write.csv(max_ent_data, file = 'data/preprocessed/residuals.csv')
